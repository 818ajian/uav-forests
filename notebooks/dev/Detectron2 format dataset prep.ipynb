{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"../..\")\n",
    "os.getcwd()\n",
    "import numpy as np\n",
    "import json\n",
    "from detectron2.structures import BoxMode\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from src.utils.dataset import split_train_val_test, get_detectron2_dataset_dicts#, #register_detectron2_datasets\n",
    "import pickle\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def split_train_val_test(samples, train_ratio, val_ratio, test_ratio=None):\n",
    "    test_ratio = test_ratio or (1.0 - train_ratio - val_ratio)\n",
    "    assert 0 < train_ratio < 1\n",
    "    assert 0 < val_ratio < 1\n",
    "    assert 0 < test_ratio < 1\n",
    "    assert 0 < train_ratio + val_ratio + test_ratio <=1\n",
    "\n",
    "    train, valtest = train_test_split(samples, train_size=train_ratio)\n",
    "    val, test = train_test_split(\n",
    "        valtest, train_size=val_ratio / (val_ratio + test_ratio))\n",
    "\n",
    "    return {\"train\": train,\n",
    "            \"val\": val,\n",
    "            \"test\": test}\n",
    "\n",
    "\n",
    "def _convert_single_bbox(bbox):\n",
    "    py, px = bbox.exterior.xy\n",
    "    return {\"bbox\": [int(min(px)), int(min(py)),\n",
    "                     int(max(px)), int(max(py))],\n",
    "            \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "            \"category_id\": 0}\n",
    "\n",
    "\n",
    "def _convert_single_patch(patch_df, images_dir,image_shape=(256, 256)):\n",
    "    patch_number = patch_df[\"patch_number\"].iloc[0]\n",
    "    file_path = os.path.join(images_dir, f\"patch_{patch_number}.tif\")\n",
    "    image_shape = image_shape or cv2.imread(file_path).shape[:2]\n",
    "    return {\"file_name\": file_path,\n",
    "            \"image_id\": patch_number,\n",
    "            \"height\": image_shape[0],\n",
    "            \"width\": image_shape[1],\n",
    "            \"annotations\": patch_df[\"bbox\"].apply(_convert_single_bbox).tolist()}\n",
    "\n",
    "\n",
    "# def get_detectron2_dataset_dicts(images_dir, patches_subset, min_bbox_area=100,\n",
    "#                                  limit_train=-1, limit_val=-1, limit_test=-1):\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"../szprotawa_patches_256_rgb_ir/\"\n",
    "min_bbox_area = 400\n",
    "\n",
    "annotations = pd.read_pickle(f\"{images_dir}/annotation.pkl\").set_geometry(\"bbox\")\n",
    "\n",
    "splits = split_train_val_test(annotations[\"patch_number\"].unique(), 0.7, 0.15, 0.15)\n",
    "patches_subset = splits['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = annotations[annotations[\"bbox\"].area >= min_bbox_area]\n",
    "annotations = annotations[annotations[\"patch_number\"].isin(patches_subset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = annotations.groupby(\"patch_number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = get_detectron2_dataset_dicts(images_dir, splits[\"val\"], min_bbox_area=200)#g.apply(_convert_single_patch, images_dir=images_dir, image_shape=(256,256)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.register(\"szp_test3\", lambda: dataset_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Metadata(name='szp_test3', thing_classes=['SickTrees'])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MetadataCatalog.get(\"szp_test3\").set(thing_classes=[\"SickTrees\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dicts = get_szprotawa_dicts(\"data/szprotawa_patches_256/\")\n",
    "# dataset_dicts = DatasetCatalog.get(\"szprotawa_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = MetadataCatalog.get(\"szp_test3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nsmpl = np.random.choice(dataset_dicts, 3)\\nrgb_axes = [0,3]\\nndvi_axes = [3,4]\\nfor d, axes in zip(smpl, (rgb_axes , rgb_axes, rgb_axes)):\\n    print(d[\"file_name\"])\\n    img = tifffile.imread(d[\"file_name\"])\\n    \\n    img = np.swapaxes(img, 0, -1)\\n    \\n    if axes == ndvi_axes:\\n        img = np.reshape(img, img.shape[:2])\\n        img[:,axes[0]:axes[1]]\\n    else:\\n        img[:,:,axes[0]:axes[1]]\\n    #print(img.shape, img.dtype)\\n    \\n    visualizer = Visualizer(img, metadata=meta, \\n                            scale=0.75)\\n    #vis = visualizer.draw_dataset_dict(d)\\n    plt.figure()\\n    plt.imshow(vis.get_image())\\n'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "smpl = np.random.choice(dataset_dicts, 3)\n",
    "rgb_axes = [0,3]\n",
    "ndvi_axes = [3,4]\n",
    "for d, axes in zip(smpl, (rgb_axes , rgb_axes, rgb_axes)):\n",
    "    print(d[\"file_name\"])\n",
    "    img = tifffile.imread(d[\"file_name\"])\n",
    "    \n",
    "    img = np.swapaxes(img, 0, -1)\n",
    "    \n",
    "    if axes == ndvi_axes:\n",
    "        img = np.reshape(img, img.shape[:2])\n",
    "        img[:,axes[0]:axes[1]]\n",
    "    else:\n",
    "        img[:,:,axes[0]:axes[1]]\n",
    "    #print(img.shape, img.dtype)\n",
    "    \n",
    "    visualizer = Visualizer(img, metadata=meta, \n",
    "                            scale=0.75)\n",
    "    #vis = visualizer.draw_dataset_dict(d)\n",
    "    plt.figure()\n",
    "    plt.imshow(vis.get_image())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 9360."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Loading config /home/h/anaconda3/envs/geopython37/lib/python3.7/site-packages/detectron2-0.1-py3.7-linux-x86_64.egg/detectron2/model_zoo/configs/COCO-Detection/../Base-RetinaNet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\nCUDNN_BENCHMARK: False\nDATALOADER:\n  ASPECT_RATIO_GROUPING: True\n  FILTER_EMPTY_ANNOTATIONS: True\n  NUM_WORKERS: 4\n  REPEAT_THRESHOLD: 0.0\n  SAMPLER_TRAIN: TrainingSampler\nDATASETS:\n  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n  PROPOSAL_FILES_TEST: ()\n  PROPOSAL_FILES_TRAIN: ()\n  TEST: ('szp_test3',)\n  TRAIN: ('szp_test3',)\nGLOBAL:\n  HACK: 1.0\nINPUT:\n  CROP:\n    ENABLED: False\n    SIZE: [0.9, 0.9]\n    TYPE: relative_range\n  FORMAT: BGR\n  MASK_FORMAT: polygon\n  MAX_SIZE_TEST: 1333\n  MAX_SIZE_TRAIN: 1333\n  MIN_SIZE_TEST: 800\n  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n  MIN_SIZE_TRAIN_SAMPLING: choice\nMODEL:\n  ANCHOR_GENERATOR:\n    ANGLES: [[-90, 0, 90]]\n    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n    NAME: DefaultAnchorGenerator\n    OFFSET: 0.0\n    SIZES: [[32, 40.31747359663594, 50.79683366298238], [64, 80.63494719327188, 101.59366732596476], [128, 161.26989438654377, 203.18733465192952], [256, 322.53978877308754, 406.37466930385904], [512, 645.0795775461751, 812.7493386077181]]\n  BACKBONE:\n    FREEZE_AT: 2\n    NAME: build_retinanet_resnet_fpn_backbone\n  DEVICE: cuda\n  FPN:\n    FUSE_TYPE: sum\n    IN_FEATURES: ['res3', 'res4', 'res5']\n    NORM: \n    OUT_CHANNELS: 256\n  KEYPOINT_ON: False\n  LOAD_PROPOSALS: False\n  MASK_ON: False\n  META_ARCHITECTURE: RetinaNet\n  PANOPTIC_FPN:\n    COMBINE:\n      ENABLED: True\n      INSTANCES_CONFIDENCE_THRESH: 0.5\n      OVERLAP_THRESH: 0.5\n      STUFF_AREA_LIMIT: 4096\n    INSTANCE_LOSS_WEIGHT: 1.0\n  PIXEL_MEAN: [103.53, 116.28, 123.675, 100.1]\n  PIXEL_STD: [1.0, 1.0, 1.0, 1.0]\n  PROPOSAL_GENERATOR:\n    MIN_SIZE: 0\n    NAME: RPN\n  RESNETS:\n    DEFORM_MODULATED: False\n    DEFORM_NUM_GROUPS: 1\n    DEFORM_ON_PER_STAGE: [False, False, False, False]\n    DEPTH: 50\n    NORM: FrozenBN\n    NUM_GROUPS: 1\n    OUT_FEATURES: ['res3', 'res4', 'res5']\n    RES2_OUT_CHANNELS: 256\n    RES5_DILATION: 1\n    STEM_OUT_CHANNELS: 64\n    STRIDE_IN_1X1: True\n    WIDTH_PER_GROUP: 64\n  RETINANET:\n    BATCH_SIZE_PER_IMAGE: 128\n    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n    FOCAL_LOSS_ALPHA: 0.25\n    FOCAL_LOSS_GAMMA: 2.0\n    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n    IOU_LABELS: [0, -1, 1]\n    IOU_THRESHOLDS: [0.4, 0.5]\n    NMS_THRESH_TEST: 0.5\n    NUM_CLASSES: 1\n    NUM_CONVS: 4\n    PRIOR_PROB: 0.01\n    SCORE_THRESH_TEST: 0.05\n    SMOOTH_L1_LOSS_BETA: 0.1\n    TOPK_CANDIDATES_TEST: 1000\n  ROI_BOX_CASCADE_HEAD:\n    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n    IOUS: (0.5, 0.6, 0.7)\n  ROI_BOX_HEAD:\n    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n    CLS_AGNOSTIC_BBOX_REG: False\n    CONV_DIM: 256\n    FC_DIM: 1024\n    NAME: \n    NORM: \n    NUM_CONV: 0\n    NUM_FC: 0\n    POOLER_RESOLUTION: 14\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n    SMOOTH_L1_BETA: 0.0\n    TRAIN_ON_PRED_BOXES: False\n  ROI_HEADS:\n    BATCH_SIZE_PER_IMAGE: 512\n    IN_FEATURES: ['res4']\n    IOU_LABELS: [0, 1]\n    IOU_THRESHOLDS: [0.5]\n    NAME: Res5ROIHeads\n    NMS_THRESH_TEST: 0.5\n    NUM_CLASSES: 80\n    POSITIVE_FRACTION: 0.25\n    PROPOSAL_APPEND_GT: True\n    SCORE_THRESH_TEST: 0.05\n  ROI_KEYPOINT_HEAD:\n    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n    LOSS_WEIGHT: 1.0\n    MIN_KEYPOINTS_PER_IMAGE: 1\n    NAME: KRCNNConvDeconvUpsampleHead\n    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n    NUM_KEYPOINTS: 17\n    POOLER_RESOLUTION: 14\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n  ROI_MASK_HEAD:\n    CLS_AGNOSTIC_MASK: False\n    CONV_DIM: 256\n    NAME: MaskRCNNConvUpsampleHead\n    NORM: \n    NUM_CONV: 0\n    POOLER_RESOLUTION: 14\n    POOLER_SAMPLING_RATIO: 0\n    POOLER_TYPE: ROIAlignV2\n  RPN:\n    BATCH_SIZE_PER_IMAGE: 256\n    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n    BOUNDARY_THRESH: -1\n    HEAD_NAME: StandardRPNHead\n    IN_FEATURES: ['res4']\n    IOU_LABELS: [0, -1, 1]\n    IOU_THRESHOLDS: [0.3, 0.7]\n    LOSS_WEIGHT: 1.0\n    NMS_THRESH: 0.7\n    POSITIVE_FRACTION: 0.5\n    POST_NMS_TOPK_TEST: 1000\n    POST_NMS_TOPK_TRAIN: 2000\n    PRE_NMS_TOPK_TEST: 6000\n    PRE_NMS_TOPK_TRAIN: 12000\n    SMOOTH_L1_BETA: 0.0\n  SEM_SEG_HEAD:\n    COMMON_STRIDE: 4\n    CONVS_DIM: 128\n    IGNORE_VALUE: 255\n    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n    LOSS_WEIGHT: 1.0\n    NAME: SemSegFPNHead\n    NORM: GN\n    NUM_CLASSES: 54\n  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_50_FPN_3x/137849486/model_final_4cafe0.pkl\nOUTPUT_DIR: ./tboard_logs/retinanet 2020-02-11T21:11/\nSEED: -1\nSOLVER:\n  BASE_LR: 0.00025\n  BIAS_LR_FACTOR: 1.0\n  CHECKPOINT_PERIOD: 250\n  GAMMA: 0.1\n  IMS_PER_BATCH: 4\n  LR_SCHEDULER_NAME: WarmupMultiStepLR\n  MAX_ITER: 10000\n  MOMENTUM: 0.9\n  STEPS: (210000, 250000)\n  WARMUP_FACTOR: 0.001\n  WARMUP_ITERS: 1000\n  WARMUP_METHOD: linear\n  WEIGHT_DECAY: 0.0001\n  WEIGHT_DECAY_BIAS: 0.0001\n  WEIGHT_DECAY_NORM: 0.0\nTEST:\n  AUG:\n    ENABLED: False\n    FLIP: True\n    MAX_SIZE: 4000\n    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n  DETECTIONS_PER_IMAGE: 5\n  EVAL_PERIOD: 200\n  EXPECTED_RESULTS: []\n  KEYPOINT_OKS_SIGMAS: []\n  PRECISE_BN:\n    ENABLED: False\n    NUM_ITER: 200\nVERSION: 2\nVIS_PERIOD: 100\n"
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "\n",
    "cfg.OUTPUT_DIR = f\"./tboard_logs/retinanet {datetime.now().isoformat().rsplit(':', 1)[0]}/\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"szp_test3\",)\n",
    "cfg.DATASETS.TEST = (\"szp_test3\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 10_000    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 250\n",
    "\n",
    "\n",
    "\n",
    "cfg.MODEL.RETINANET.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.RETINANET.NUM_CLASSES = 1  # only has one class (ballon)\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 200#2_000 #200\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 5\n",
    "\n",
    "cfg.VIS_PERIOD = 100\n",
    "cfg.MODEL.PIXEL_MEAN = [103.53, 116.28, 123.675, 100.1] #ostatnia wartość wpisana z palca\n",
    "cfg.MODEL.PIXEL_STD =  [1.0, 1.0, 1.0, 1.0] #ostatnia wartość wpisana z palca\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(cfg.OUTPUT_DIR):\n",
    "    os.makedirs(cfg.OUTPUT_DIR)\n",
    "with open(os.path.join(cfg.OUTPUT_DIR, \"config.yaml\"), 'w') as f:\n",
    "    f.write(cfg.dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    \n",
    "    \n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_dir=cfg.OUTPUT_DIR+\"/eval/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\u001b[32m[02/11 21:11:33 d2.engine.defaults]: \u001b[0mModel:\nRetinaNet(\n  (backbone): FPN(\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (top_block): LastLevelP6P7(\n      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    )\n    (bottom_up): ResNet(\n      (stem): BasicStem(\n        (conv1): Conv2d(\n          4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n        )\n      )\n      (res2): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n      )\n      (res3): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n      )\n      (res4): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (4): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (5): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n      )\n      (res5): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n      )\n    )\n  )\n  (head): RetinaNetHead(\n    (cls_subnet): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (7): ReLU()\n    )\n    (bbox_subnet): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (7): ReLU()\n    )\n    (cls_score): Conv2d(256, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (anchor_generator): DefaultAnchorGenerator(\n    (cell_anchors): BufferList()\n  )\n)\n\u001b[32m[02/11 21:11:33 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 192 images left.\n\u001b[32m[02/11 21:11:33 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n\u001b[36m|  category  | #instances   |\n|:----------:|:-------------|\n| SickTrees  | 223          |\n|            |              |\u001b[0m\n\u001b[32m[02/11 21:11:33 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n\u001b[32m[02/11 21:11:33 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n'backbone.bottom_up.stem.conv1.weight' has shape (64, 3, 7, 7) in the checkpoint but (64, 4, 7, 7) in the model! Skipped.\n'head.cls_score.weight' has shape (720, 256, 3, 3) in the checkpoint but (9, 256, 3, 3) in the model! Skipped.\n'head.cls_score.bias' has shape (720,) in the checkpoint but (9,) in the model! Skipped.\n\u001b[32m[02/11 21:11:33 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n\u001b[32m[02/11 21:11:40 d2.utils.events]: \u001b[0meta: 0:58:53  iter: 19  total_loss: 1.792  loss_cls: 1.106  loss_box_reg: 0.673  time: 0.3536  data_time: 0.0113  lr: 0.000005  max_mem: 2550M\n\u001b[32m[02/11 21:11:48 d2.utils.events]: \u001b[0meta: 0:59:47  iter: 39  total_loss: 1.731  loss_cls: 1.091  loss_box_reg: 0.640  time: 0.3608  data_time: 0.0069  lr: 0.000010  max_mem: 2550M\n\u001b[32m[02/11 21:11:55 d2.utils.events]: \u001b[0meta: 1:00:05  iter: 59  total_loss: 1.569  loss_cls: 1.058  loss_box_reg: 0.505  time: 0.3622  data_time: 0.0066  lr: 0.000015  max_mem: 2550M\n\u001b[32m[02/11 21:12:02 d2.utils.events]: \u001b[0meta: 0:59:25  iter: 79  total_loss: 1.484  loss_cls: 1.016  loss_box_reg: 0.475  time: 0.3602  data_time: 0.0068  lr: 0.000020  max_mem: 2550M\n\u001b[32m[02/11 21:12:09 d2.utils.events]: \u001b[0meta: 0:58:29  iter: 99  total_loss: 1.421  loss_cls: 0.962  loss_box_reg: 0.462  time: 0.3557  data_time: 0.0064  lr: 0.000025  max_mem: 2550M\n\u001b[32m[02/11 21:12:16 d2.utils.events]: \u001b[0meta: 0:58:38  iter: 119  total_loss: 1.373  loss_cls: 0.925  loss_box_reg: 0.451  time: 0.3566  data_time: 0.0068  lr: 0.000030  max_mem: 2550M\n\u001b[32m[02/11 21:12:23 d2.utils.events]: \u001b[0meta: 0:58:18  iter: 139  total_loss: 1.330  loss_cls: 0.880  loss_box_reg: 0.455  time: 0.3553  data_time: 0.0066  lr: 0.000035  max_mem: 2550M\n\u001b[32m[02/11 21:12:30 d2.utils.events]: \u001b[0meta: 0:58:06  iter: 159  total_loss: 1.265  loss_cls: 0.833  loss_box_reg: 0.434  time: 0.3541  data_time: 0.0065  lr: 0.000040  max_mem: 2550M\n\u001b[32m[02/11 21:12:37 d2.utils.events]: \u001b[0meta: 0:58:04  iter: 179  total_loss: 1.252  loss_cls: 0.845  loss_box_reg: 0.423  time: 0.3547  data_time: 0.0070  lr: 0.000045  max_mem: 2550M\n\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[02/11 21:12:44 d2.engine.train_loop]: \u001b[0mException during training:\nTraceback (most recent call last):\n  File \"/home/h/anaconda3/envs/geopython37/lib/python3.7/site-packages/detectron2-0.1-py3.7-linux-x86_64.egg/detectron2/engine/train_loop.py\", line 133, in train\n    self.after_step()\n  File \"/home/h/anaconda3/envs/geopython37/lib/python3.7/site-packages/detectron2-0.1-py3.7-linux-x86_64.egg/detectron2/engine/train_loop.py\", line 153, in after_step\n    h.after_step()\n  File \"/home/h/anaconda3/envs/geopython37/lib/python3.7/site-packages/detectron2-0.1-py3.7-linux-x86_64.egg/detectron2/engine/hooks.py\", line 347, in after_step\n    self._do_eval()\n  File \"/home/h/anaconda3/envs/geopython37/lib/python3.7/site-packages/detectron2-0.1-py3.7-linux-x86_64.egg/detectron2/engine/hooks.py\", line 321, in _do_eval\n    results = self._func()\n  File \"/home/h/anaconda3/envs/geopython37/lib/python3.7/site-packages/detectron2-0.1-py3.7-linux-x86_64.egg/detectron2/engine/defaults.py\", line 331, in test_and_save_results\n    self._last_eval_results = self.test(self.cfg, self.model)\n  File \"/home/h/anaconda3/envs/geopython37/lib/python3.7/site-packages/detectron2-0.1-py3.7-linux-x86_64.egg/detectron2/engine/defaults.py\", line 486, in test\n    evaluator = cls.build_evaluator(cfg, dataset_name)\nTypeError: build_evaluator() missing 1 required positional argument: 'dataset_name'\n\u001b[32m[02/11 21:12:44 d2.engine.hooks]: \u001b[0mOverall training speed: 197 iterations in 0:01:10 (0.3564 s / it)\n\u001b[32m[02/11 21:12:44 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:10 (0:00:00 on hooks)\n"
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'./tboard_logs/retinanet 2020-02-11T21:11/'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Checkpoint ./tboard_logs/retinanet 2020-02-11T21:11/model_final.pth not found!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0f4f3d08d223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDETECTIONS_PER_IMAGE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefaultPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TEST\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/geopython37/lib/python3.7/site-packages/detectron2-0.1-py3.7-linux-x86_64.egg/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetectionCheckpointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mcheckpointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         self.transform_gen = T.ResizeShortestEdge(\n",
      "\u001b[0;32m~/anaconda3/envs/geopython37/lib/python3.7/site-packages/fvcore/common/checkpoint.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Checkpoint {} not found!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Checkpoint ./tboard_logs/retinanet 2020-02-11T21:11/model_final.pth not found!"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.3\n",
    "cfg.DATASETS.TEST = (\"szp_test3\", )\n",
    "cfg.TEST.SCORE_THRESHOLD = 0.3\n",
    "cfg.TEST.SCORE_THRESH = 0.3\n",
    "\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 10\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "predictor.cfg[\"TEST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "# dataset_dicts = DatasetCatalog.get(\"szprotawa_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in np.random.choice(dataset_dicts, 1):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:,:,::-1].copy(),\n",
    "                   metadata=meta, \n",
    "                   scale=0.8)\n",
    "    vis = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    f, a = plt.subplots(1,2, figsize=(10,5))\n",
    "    a[0].imshow(vis.get_image())\n",
    "    \n",
    "    v = Visualizer(im[:,:,::-1].copy(),\n",
    "                   metadata=meta, \n",
    "                   scale=0.8)\n",
    "    vis = v.draw_dataset_dict(d)\n",
    "    a[1].imshow(vis.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = register_detectron2_datasets(\"szprott\", \"./data/szprotawa_patches_256/\", 0.7, 0.15, 0.15, 100, {'test': splits['test'][:500]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import DatasetEvaluator, COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "\n",
    "\n",
    "evaluator = COCOEvaluator(\"szprottx_test\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"szprott_test\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "# another equivalent way is to use trainer.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}